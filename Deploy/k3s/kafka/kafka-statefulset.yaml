apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka-statefulset
spec:
  replicas: 1
  serviceName: kafka-headless
  selector:
    matchLabels:
      app: kafka-pod
  template:
    metadata:
      labels:
        app: kafka-pod
    spec:
      enableServiceLinks: false
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.4
        ports:
        - containerPort: 9092  
        env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: KAFKA_REPLICATION_FACTOR
            value: "1" # match with the number of replicas
          - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
            value: "1" # match with the number of replicas          
          - name: KAFKA_LOG_RETENTION_BYTES
            value: "-1"
          - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
            value: "500"
          - name: KAFKA_LOG_RETENTION_MS
            value: "60000"
          - name: KAFKA_ZOOKEEPER_CONNECT
            value: "zookeeper:2181"
          - name: KAFKA_ADVERTISED_LISTENERS
            value: "PLAINTEXT://$(HOSTNAME).kafka-headless.default.svc.cluster.local:9092"
          - name: KAFKA_LISTENERS
            value: "PLAINTEXT://0.0.0.0:9092"
          - name: KAFKA_LISTENER_SECURITY_PROTOCOL
            value: "PLAINTEXT"
          - name: KAFKA_LISTENER_NAME_INTERNAL
            value: "INTERNAL"
          - name: KAFKA_INTER_BROKER_LISTENER_NAME
            value: "PLAINTEXT"
        command:
          - sh
          - -c
          - |
            export KAFKA_BROKER_ID=$(hostname | awk -F'-' '{print $NF}')
            exec /etc/confluent/docker/run
        volumeMounts:
          - name: kafka-data
            mountPath: /var/lib/kafka
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteMany"]
        storageClassName: nfs-kafka
        resources:
          requests:
            storage: 2Gi